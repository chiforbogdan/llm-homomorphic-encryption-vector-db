{
    "patent_title": "AIMING METHOD AND DEVICE FOR SHOOTING GAME",
    "patent_number": "14903605",
    "patent_summary": "<SOH> SUMMARY OF THE INVENTION <EOH>In view of the disadvantages in the prior art, an objective of the present invention is intended to provide an aiming method for a shooting game, which facilitates accurate steering and aiming of a virtual camera and can also effectively improve the game experience. In order to achieve the above objective, the present invention adopts the following technical solution: An aiming method for a shooting game, which is applied to a mobile terminal having a touch display screen, characterized in that the aiming method comprises the following steps: a positioning step: acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation step: acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting step: acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. Preferably, the rotation step comprises the following sub-steps: an object determination step: when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary step: creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination step: obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application step: applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment step: if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination step. Preferably, the sensor in the adjusting step is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. Preferably, the sensor in the adjusting step is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Preferably, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. The present invention further proposes an aiming device for a shooting game, which comprises the following modules: a positioning module for acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation module for acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting module for acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. Preferably, the rotation module comprises the following sub-modules: an object determination module for, when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary module for creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination module for obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application module for applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment module for, if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination module. Preferably, the sensor in the adjusting module is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. Preferably, the sensor in the adjusting module is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Preferably, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. The beneficial effects of the present invention are as follows: the method facilitates accurate steering and aiming of the virtual camera, and can also effectively improve the player's experience of the game; and the present solution employs a way of combining a touch-screen and a gravity sensor or a gyroscope, that is, a preliminary rotation of a virtual camera is collimated after a contact object is detected, and a rotation angle of the virtual camera is adjusted accurately via the gravity sensor or the gyroscope, thereby facilitating the accurate aiming of the virtual camera at the contact object, and further improving the player experience during the game.",
    "patent_claims": "1. An aiming method for a shooting game, which is applied to a mobile terminal having a touch display screen, wherein the aiming method comprises the following steps: a positioning step: acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation step: acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting step: acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. 2. The aiming method for a shooting game of claim 1, wherein the rotation step comprises the following sub-steps: an object determination step: when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary step: creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination step: obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application step: applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment step: if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination step. 3. The aiming method for a shooting game of claim 1, wherein the sensor in the adjusting step is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. 4. The aiming method for a shooting game of claim 1, wherein the sensor in the adjusting step is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. 5. The aiming method for a shooting game of claim 4, wherein the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. 6. An aiming device for a shooting game, which is applied to a mobile terminal having a touch display screen, wherein the aiming device comprises the following modules: a positioning module for acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation module for acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting module for acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. 7. The aiming device for a shooting game of claim 6, wherein the rotation module comprises the following sub-modules: an object determination module for, when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary module for creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination module for obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application module for applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment module for, if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination module. 8. The aiming device for a shooting game of claim 6, wherein the sensor in the adjusting module is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. 9. The aiming device for a shooting game of claim 6, wherein the sensor in the adjusting module is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. 10. The aiming device for a shooting game of claim 9, wherein the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1.",
    "patent_description": "TECHNICAL FIELD The present invention relates to an aiming technique in a mobile game and, in particular, to an aiming method and device for a shooting game on a mobile touch-screen terminal. BACKGROUND The mobile game is an electronic game service that a user operates on a mobile touch-screen terminal, e.g., a platform such as a mobile phone, a tablet computer, via a mobile communication network, which comprises a chess and card game, a role-playing game, a strategy game, an action game, etc. At present, the shooting game, as one of the action games, typically uses the following solution to implement aiming and shooting by means of a virtual camera: a double-joystick operation solution that is used by both the mainstream FPS (e.g., the Modern Warfare series) and TPS (e.g., the Frontline Commando series) on a mobile touch-screen terminal at present. Such a solution is to simulate two joysticks on a touch screen, the left joystick controlling the movement of a target and the right joystick controlling a lens of the virtual camera to aim and shoot. This solution seems reasonable, but actually is not ergonomic: firstly, the right joystick is used to replace mouse operation, meaning that a series of complex, fine and fast operations that can only be completed with the entire arm previously are required to be completed entirely by the right thumb, which will bring great difficulties to the player during steering and aiming and cause the result to be riddled with errors; and secondly, a virtual joystick cannot provide feedback to a hand of the player like a real joystick or a mouse, and thus the user needs to perform observation and calibration with his/her own eyes for any operation, which further increase the difficulty of the operation. The above two points may increase user experience frustration during the game and decrease the overall perception, so that the FPS and the TPS on the mobile touch-screen apparatus has narrow audience and is difficult to develop, and thus is far from the market effect that should be obtained. SUMMARY OF THE INVENTION In view of the disadvantages in the prior art, an objective of the present invention is intended to provide an aiming method for a shooting game, which facilitates accurate steering and aiming of a virtual camera and can also effectively improve the game experience. In order to achieve the above objective, the present invention adopts the following technical solution: An aiming method for a shooting game, which is applied to a mobile terminal having a touch display screen, characterized in that the aiming method comprises the following steps: a positioning step: acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation step: acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting step: acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. Preferably, the rotation step comprises the following sub-steps: an object determination step: when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary step: creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination step: obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application step: applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment step: if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination step. Preferably, the sensor in the adjusting step is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. Preferably, the sensor in the adjusting step is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Preferably, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. The present invention further proposes an aiming device for a shooting game, which comprises the following modules: a positioning module for acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation module for acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting module for acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. Preferably, the rotation module comprises the following sub-modules: an object determination module for, when detecting that there is contact on the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary module for creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination module for obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application module for applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment module for, if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination module. Preferably, the sensor in the adjusting module is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. Preferably, the sensor in the adjusting module is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Preferably, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. The beneficial effects of the present invention are as follows: the method facilitates accurate steering and aiming of the virtual camera, and can also effectively improve the player's experience of the game; and the present solution employs a way of combining a touch-screen and a gravity sensor or a gyroscope, that is, a preliminary rotation of a virtual camera is collimated after a contact object is detected, and a rotation angle of the virtual camera is adjusted accurately via the gravity sensor or the gyroscope, thereby facilitating the accurate aiming of the virtual camera at the contact object, and further improving the player experience during the game. BRIEF DESCRIPTION OF THE DRAWINGS FIG. 1 is a flow chart of a preferred implementation of an aiming method for a shooting game of the present invention. FIG. 2 is a flow chart of a preferred implementation of a rotation step in an aiming method for a shooting game of the present invention. DETAILED DESCRIPTION The present invention will be further described below in conjunction with the drawings and the particular embodiments. Please refer to FIG. 1, the present embodiment relates to an aiming method for a shooting game, which is applied to a mobile terminal having a touch display screen, the aiming method comprising the following steps: A positioning step S1: acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface. The virtual camera is an \u201ceye\u201d of a player in a 3D game and a scene photographed by the virtual camera is a scene that the player sees on the screen, there being only one unique virtual camera in one scene throughout the game. The current rotation angle of the virtual camera is a quaternion, wherein the quaternion can be seen as a four-dimensional vector for representing the rotation of an object in a space. A rotation step S2: acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position. In particular, this is a step of coarsely adjusting the position of a front sight during the game, that is, once detecting that there is contact in the game interface, the virtual camera rotates and aligns with a range where there is contact, so that the range where there is contact can be displayed on a preset position on the touch display screen of the mobile terminal, wherein the preset position can be the center of the screen. This step can be implemented by clicking the touch-screen, corresponding to the operation in which the player rapidly slides a mouse with his/her shoulder and elbow, steers and approximately aims at the target in a keyboard-mouse FPS, thereby completing the operation of a large rotation of the virtual camera, and at this time, the rotation angle is always greater than 10 degrees, and also, the rotation angle of the large rotation of the virtual camera is greater than how many degrees can certainly be set according to the actual conditions. An adjusting step S3: acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. In particular, this is a step of finely adjusting the position of the front sight during the game, and when the contact range in the game is displayed at the preset position on the touch display screen of the mobile terminal, accurate aiming is achieved with a sensor. This step can be implemented by waggling the mobile terminal and via the sensor, corresponding to the operation in which the player gently moves the mouse with his/her wrist and aims at the head of the target in the keyboard-mouse FPS, thereby completing the operation of a slight rotation of the virtual camera, and at this time, the rotation angle is always smaller than 5 degrees, and also, the rotation angle of the slight rotation of the virtual camera is smaller than how many degrees can certainly be set according to the actual conditions. As shown in FIG. 2, the rotation step S2 may comprise the following sub-steps: An object determination step S2a: when clicking the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position, touchPosition, of the contact object. An auxiliary step S2b: creating, according to an auxiliary function, an auxiliary ray, Ray, with a near clip plane of the virtual camera as a start point and passing through the coordinate position, touchPosition, and acquiring a rotation angle, touchQ, of the auxiliary ray, Ray. This auxiliary function can be a Unity function, ScreenPointToRay. An increment determination step S2c: obtaining an intermediate interpolation, lerpQ, between the current rotation angle of the virtual camera and the rotation angle, touchQ, of the auxiliary ray by means of a cyclical function. This cyclical function can be any one of an Update, FixedUpdate, InvokeRepeating function and a coroutine while function. The intermediate interpolation, lerpQ, is a quaternion which continually gets closer to the direction of the auxiliary ray, because a quaternion is a four-dimensional vector that can be normalized and is suitable for various types of interpolations, such as a linear interpolation algorithm: q(t)=(1\u2212t)q1+t q2/\u2225(1\u2212t)q1+tq2\u2225. For more information, reference can be made to \u201cResearch and Application of Smooth Rotation on the Role in the Game Use of Quaternion Interpolation Algorithm\u201d by Zheng Jun, YINSHAN ACADEMIC JOURNAL (NATURAL SCIENCE), no. 1, 2012. An increment application step S2d: applying the intermediate interpolation, lerpQ, to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, lerpQ, and recording a rotation angle of the virtual camera after a rotation. A judgment step S2e: if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera, with the rotation angle of the virtual camera being consistent with the rotation angle of the auxiliary ray, Ray at this time; otherwise, returning to the increment determination step S2c. Preferably, the sensor in the adjusting step can be a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is acquired to control the rotation angle of the virtual camera. In particular, the values of a gravity parameter on the X-axis and the Y-axis are acquired after the gyroscope is started, and the values on the X-axis and the Y-axis are multiplied by a certain amplification factor coefficient, that is, the acquired values on the X-axis and the Y-axis are used as a basic value, the amplification factor coefficient of this basic value is pre-defined; a setting is customized that, the greater the amplification factor coefficient is, the greater the amplitude of rotation of the virtual camera is; and the amplified values on the X-axis and the Y-axis are used as an Euler angle of the quaternion and applied to the virtual camera. The gyroscope determines that a numerical value of the spatial attitude of the object is varying continuously along with the rotation of the object, and the values of the gravity parameter on the X-axis and the Y-axis continually obtained are multiplied by the customized amplification factor so as to obtain a final rotation angle of the virtual camera required to be obtained. Certainly, the sensor in the adjusting step may be a gravity sensor and may also be other sensors that are able to acquire the corresponding waggle angle. In the adjusting step, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Furthermore, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. In particular, the acceleration value of the gravity sensor in the mobile terminal can be acquired in real time according to Input.acceleration, this acceleration value being a three-dimensional vector, wherein the magnitude of the numerical value on the X-axis ranges from \u22121 to 1, the magnitude of the numerical value on the Y-axis ranges from \u22121 to 1, and the magnitude of the numerical value on the Z-axis ranges from \u22121 to 1. The particular principle thereof is as follows: put a mobile phone flat with the front face facing up, and according to the right hand rule, put the right hand out with the palm facing up, close together four fingers so that they get perpendicular to the thumb, wherein a direction indicated by the thumb is the X-axis on which the value is a three-dimensional vector (0, 0, 0), a direction indicated by the four fingers is the Y-axis on which the value is a three-dimensional vector (0, 0, 0) and a direction which is perpendicular to the palm and goes upwards is the Z-axis on which the value is a three-dimensional vector (0, 0, \u22121); and when the mobile terminal is rotated, assuming that there is a vector which is vertical downwards, then the values on the X-axis, the Y-axis and the Z-axis are respectively compared to this vector, when the directions are consistent, we get 1, when the directions are opposite, we get \u22121, and when the directions are perpendicular, 0. The changed numerical values on the X-axis and the Y-axis are multiplied by a pre-defined coefficient and then applied to the values on the X-axis and the Y-axis of the Euler angle in the quaternion, so as to obtain a quaternion and it is assumed that the name is defined as accQ. That is, a three-dimensional vector is continuously obtained according to different spatial attitudes of the mobile terminal, and this three-dimensional vector also changes continuously when the mobile terminal is rotated, e.g., the value on the X-axis changes 0.1, the value on the Y-axis changes 0.2, then a three-dimensional vector (0.1, 0.2, 0) is used for representation. The pre-defined coefficient is how many degrees the rotation changes during a unit time, i.e. degrees/second, for example, it can be pre-defined that the rotation changes 5 degrees each time the value on the X-axis changes 0.1, that is, the greater the pre-defined coefficient is, the greater the amplitude of rotation of the virtual camera is when the pre-defined coefficient is applied to the virtual camera. An included angle between a real-time quaternion accQ and a previous quaternion accQ thereof is calculated, and the real-time quaternion accQ is applied only when the included angle is greater than a preset threshold. In particular, when judging whether the included angle is greater than the preset threshold, a rotation angle lastQ can be obtained according to the real-time quaternion accQ and the previous quaternion accQ thereof, 1 degree being approximately 0.0174533 radians according to angle and radian conversion, and the radian of lastQ is compared to 0.0174533, if lastQ is greater than 0.0174533, then lastQ is considered to be greater than the preset threshold. The Euler angle of the quaternion accQ is applied to the camera, and the camera is rotationally moved along with the spatial attitude of the mobile terminal, so as to complete the process of accurately aiming at the contact object. In particular, a quaternion is a four-dimensional vector (x, y, z, w). An operation such as rotation of a spatial object is implemented with a 4\u00d74 matrix, and we cannot simply take a rotation angle to a vector. An Euler angle is a three-dimensional vector (x, y, z) representing rotation angles on the X-axis, the Y-axis and the Z-axis, and if the rotation angles on the X-axis and the Y-axis are taken, transformation from a quaternion to an Euler angle can be implemented, e.g. encapsulated as Quaternion.eulerAngles in a unity. The present embodiment further proposes an aiming device for a shooting game, which comprises the following modules: a positioning module for acquiring a current rotation angle of a virtual camera when the mobile terminal is in a game interface; a rotation module for acquiring a coordinate position of a contact object when detecting that there is contact on the game interface, so that the current rotation angle of the virtual camera matches the coordinate position; and an adjusting module for acquiring a corresponding waggle angle via a sensor of the mobile terminal when detecting that the mobile terminal is waggling, so that the current rotation angle of the virtual camera matches the waggle angle. Preferably, the rotation module comprises the following sub-modules: an object determination module for, when clicking the game interface, detecting all list objects that are in a touch state, obtaining a list object that is in a game interface clicking state and denoting same as the contact object, and acquiring the coordinate position of the contact object; an auxiliary module for creating, according to an auxiliary function, an auxiliary ray with a near clip plane of the virtual camera as a start point and passing through the coordinate position, and acquiring a rotation angle of the auxiliary ray; an increment determination module for obtaining an intermediate interpolation between the current rotation angle of the virtual camera and the rotation angle of the auxiliary ray by means of a cyclical function; an increment application module for applying the intermediate interpolation to the virtual camera, so that an amplitude of rotation of the virtual camera is equal to the intermediate interpolation, and recording a rotation angle of the virtual camera after a rotation; and a judgment module for, if the rotation angle of the virtual camera after the rotation matches the rotation angle of the auxiliary ray, completing a preliminary movement of the virtual camera; otherwise, returning to the increment determination module. Preferably, the sensor in the adjusting module is a gyroscope, wherein, by starting the gyroscope, a gravity parameter value of the gyroscope is obtained to control the rotation angle of the virtual camera. Preferably, the sensor in the adjusting module is a gravity sensor, wherein, by starting the gravity sensor, an acceleration value of the gravity sensor is acquired in real time; and an angle variation of the acceleration value generated per second is judged, and if the angle variation exceeds a preset threshold, the rotation angle of the virtual camera is controlled according to the angle variation after the rotation. Preferably, the acceleration value is a three-dimensional vector value which is constituted by an X-axis acceleration value, a Y-axis acceleration value and a Z-axis acceleration value, wherein the magnitudes of the X-axis acceleration value, the Y-axis acceleration value and the Z-axis acceleration value all range from \u22121 to 1. For a person skilled in the art, various other corresponding changes and modifications can be made according to the technical solutions and concepts described above, and all of these changes and modifications should fall within the scope of the claims of the present invention.",
    "patent_mail": "Subject: Important Patent Details - Aiming Method for Shooting Games\n\nDear [Colleague's Name],\n\nI hope this email finds you well. I wanted to share some critical details regarding our recent patent on an innovative aiming method for shooting games that we are incredibly excited about. This method is designed specifically for mobile terminals equipped with touch display screens, and I believe it has the potential to significantly enhance user experience in mobile gaming.\n\n**Patent Overview:**\n\nThe patent encompasses an aiming method that includes the following key steps:\n\n1. **Positioning Step:** The method begins with acquiring the current rotation angle of a virtual camera when the mobile terminal is in a game interface.\n   \n2. **Rotation Step:** When contact is detected on the game interface, the method acquires the coordinate position of the contact object, aligning the current rotation angle of the virtual camera with this position.\n   \n3. **Adjusting Step:** The method employs sensors within the mobile terminal to detect waggling motions and adjusts the virtual camera's rotation angle accordingly.\n\n**Detailed Claims:**\n- The rotation step includes sub-steps for determining contact objects, creating auxiliary rays, and interpolating rotation angles to ensure smooth transitions.\n- Sensors such as gyroscopes and gravity sensors play a crucial role in fine-tuning the aiming adjustments based on real-time data.\n\n**Collaborators:**\nI am proud to state that I co-authored this patent with my colleagues:\n- John Doe (Employee ID: 1000)\n- Michael Snow (Employee ID: 2000)\n- Summer Winter (Employee ID: 3000)\n\nIf you have any questions or require further details about the patent, please feel free to reach out. I believe there are numerous opportunities to leverage this technology in our future projects.\n\nBest regards,\n\n[Your Name]  \n[Your Position]  \n[Your Company Name]  \n[Your Contact Information]  "
}